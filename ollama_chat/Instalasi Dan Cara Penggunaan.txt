# Project: Chat AI dengan Model Gemma 3:1B 

Persiapan:
1. Install Node.js dari https://nodejs.org
2. Install Ollama dari https://ollama.com
3. Download model AI: buka terminal lalu jalankan: ollama pull gemma3:1b
4. Jalankan model AI: ollama run gemma3:1b (biarkan terminal ini tetap terbuka)

Instalasi Project:
5. Clone atau extract folder project ke komputer
6. Buka terminal di folder project
7. Jalankan perintah: npm install express node-fetch@2

Menjalankan Project:
8. Jalankan server backend: node server.js
9. Buka browser dan akses: http://localhost:3000

Struktur Folder:
- server.js = server Node.js (menghubungkan frontend ke model)
- public/index.html = tampilan UI chat (user input dan chat bubble)
- package.json = berisi dependency project
- .gitignore = mengabaikan folder node_modules saat pakai Git

Fitur Aplikasi:
- Input teks pertanyaan lewat form browser
- Kirim pertanyaan ke model AI lokal (Gemma 3:1B via Ollama)
- Balasan AI ditampilkan dalam bubble chat rapi
- Efek loading "Gemma sedang mengetik..." saat tunggu jawaban
- Scroll otomatis ke bawah saat ada chat baru
- Tekan Enter = kirim pesan
- UI responsif dan bersih

Cara Testing:
1. Pastikan model sedang aktif: jalankan `ollama run gemma3:1b`
2. Jalankan server: `node server.js`
3. Akses: http://localhost:3000 di browser
4. Ketik pertanyaan, contoh: Apa itu machine learning?
5. Jika AI menjawab di layar, maka aplikasi BERHASIL dijalankan

Catatan:
- Jika muncul error "require is not defined", hapus "type": "module" dari package.json
- Gunakan node-fetch versi 2 agar kompatibel dengan require()
- Port default adalah 3000, jika bentrok ubah di server.js
- File .gitignore harus ada agar node_modules tidak masuk Git
